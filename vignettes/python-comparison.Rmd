---
title: "Comparison with Python Logging Solutions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Comparison with Python Logging Solutions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(logthis)
```

## Introduction

If you're coming from Python and familiar with its logging ecosystem, this guide will help you understand how `logthis` compares to popular Python logging solutions. While R and Python have different idioms, `logthis` provides enterprise-level logging capabilities comparable to Python's mature frameworks.

This comparison covers:

- **Python's built-in `logging` module** - The standard library solution
- **loguru** - A modern, simplified logging library
- **structlog** - A structured logging framework

## Architecture Overview

### Conceptual Comparison

All four frameworks share similar architectural concepts, but with different implementations:

| Component | Python logging | loguru | structlog | logthis |
|-----------|---------------|---------|-----------|---------|
| **Core Design** | Hierarchical namespace loggers | Single pre-configured logger | Structured output focus | Functional composition |
| **Message Routing** | Loggers → Handlers → Output | Direct output with sinks | Processors → Output | Loggers → Receivers → Output |
| **Configuration** | Imperative (dict/file) | Minimal/zero config | Pipeline-based | Pipe-friendly functional |
| **Filtering** | Logger + Handler levels | Sink-level filtering | Processor-based | Two-level (logger + receiver) |
| **State Management** | Global registry | Global instance | Bound loggers | Explicit objects |

### Key Architectural Similarities

**logthis most closely resembles Python's `logging` module** in its handler/receiver pattern and two-level filtering, but uses **functional composition** inspired by R's pipe operators (`%>%`) rather than imperative configuration.

## Feature Comparison

### 1. Python's Built-in `logging` Module

Python's standard library logging module uses a hierarchical namespace with loggers, handlers, and formatters.

**Python code:**

```python
import logging

# Configure logger with handler
logger = logging.getLogger('myapp')
logger.setLevel(logging.DEBUG)

handler = logging.FileHandler('app.log')
handler.setLevel(logging.WARNING)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

logger.debug("This won't appear in file")
logger.warning("This will appear in file")
```

**Equivalent in logthis:**

```{r python-logging-equiv, eval=FALSE}
log_this <- logger() %>%
  with_receivers(
    to_text() %>%
      on_local(path = "app.log") %>%
      with_limits(lower = WARNING)
  ) %>%
  with_limits(lower = DEBUG)

log_this(DEBUG("This won't appear in file"))
log_this(WARNING("This will appear in file"))
```

**Key Differences:**

- **Namespace hierarchy**: Python uses `logger.child.grandchild` propagation; logthis uses scope-based masking
- **Global state**: Python stores loggers in a global registry; logthis uses explicit logger objects
- **Configuration**: Python uses dict-based or file-based config; logthis uses pipe-based functional composition

### 2. loguru - Simplified Logging

loguru provides a pre-configured, easy-to-use logging interface with a single global logger.

**Python code:**

```python
from loguru import logger

# Pre-configured, just add sinks
logger.add("app.log", rotation="500 MB", level="WARNING")
logger.add("debug.log", level="DEBUG")

logger.debug("Detailed debug info")
logger.warning("This goes to both files")
```

**Equivalent in logthis:**

```{r loguru-equiv, eval=FALSE}
log_this <- logger() %>%
  with_receivers(
    to_text() %>%
      on_local(path = "app.log", max_size = 5e8) %>%
      with_limits(lower = WARNING),
    to_text() %>%
      on_local(path = "debug.log") %>%
      with_limits(lower = DEBUG)
  )

log_this(DEBUG("Detailed debug info"))
log_this(WARNING("This goes to both files"))
```

**Key Differences:**

- **Single global logger**: loguru has one logger instance; logthis supports multiple independent loggers
- **Automatic rotation**: loguru has built-in file rotation; logthis requires manual configuration
- **Testing**: Both support easy testing (loguru's `_default` handler removal, logthis's `to_itself()`)

**Similarities:**

- Pre-configured defaults for quick setup
- Simple, clean API
- Support for multiple output destinations

### 3. structlog - Structured Logging

structlog focuses on structured output (JSON, Logfmt) with a processor chain architecture.

**Python code:**

```python
import structlog

structlog.configure(
    processors=[
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ]
)

logger = structlog.get_logger()
logger = logger.bind(user_id="12345")  # Context binding
logger.info("user_action", action="login")
```

**Equivalent in logthis:**

```{r structlog-equiv, eval=FALSE}
log_this <- logger() %>%
  with_receivers(to_json() %>% on_local(path = "app.jsonl")) %>%
  with_tags("user:12345")  # Tag-based context

log_this(NOTE("user_action", action = "login"))
```

**Key Differences:**

- **Processor chain**: structlog uses explicit processing pipeline; logthis uses receiver pattern
- **Integration focus**: structlog wraps existing loggers; logthis is standalone
- **Context managers**: Python-specific context binding; logthis uses scope-based masking

**Similarities:**

- First-class support for structured output (JSON)
- Context/metadata binding (structlog's `bind()`, logthis's `with_tags()`)
- Composable, customizable architecture

## Common Tasks: Side-by-Side

### Basic Setup

**Python (logging):**
```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logger.info("Started")
```

**logthis:**
```{r basic-setup, eval=FALSE}
log_this <- logger() %>%
  with_receivers(to_console()) %>%
  with_limits(lower = NOTE)
log_this(NOTE("Started"))
```

### Multiple Outputs

**Python (loguru):**
```python
logger.add("file.log", level="ERROR")
logger.add("debug.log", level="DEBUG")
```

**logthis:**
```{r multi-output, eval=FALSE}
log_this <- logger() %>%
  with_receivers(
    to_text() %>% on_local("file.log") %>% with_limits(lower = ERROR),
    to_text() %>% on_local("debug.log") %>% with_limits(lower = DEBUG)
  )
```

### Structured/JSON Logging

**Python (structlog):**
```python
logger.info("event", user_id=123, action="login")
```

**logthis:**
```{r structured, eval=FALSE}
log_this(NOTE("event", user_id = 123, action = "login"))
```

### Context Binding

**Python (structlog):**
```python
logger = logger.bind(request_id="abc-123")
logger.info("Processing request")
```

**logthis:**
```{r context-binding, eval=FALSE}
log_this <- log_this %>% with_tags("request:abc-123")
log_this(NOTE("Processing request"))
```

### Error Handling

**Python (loguru):**
```python
@logger.catch
def risky_function():
    1 / 0
```

**logthis:**
```{r error-handling, eval=FALSE}
tryCatch({
  1 / 0
}, error = function(e) {
  log_this(ERROR(paste("Error:", e$message)))
})
```

## Unique Features of logthis

### 1. Functional Composition

Pure R pipe-based design with no global state modification:

```{r functional-composition, eval=FALSE}
# Immutable transformations
base_logger <- logger() %>% with_receivers(to_console())
debug_logger <- base_logger %>% with_limits(lower = DEBUG)
prod_logger <- base_logger %>% with_limits(lower = WARNING)

# base_logger is unchanged
```

### 2. Scope-Based Logger Enhancement

R's lexical scoping enables temporary logger modifications:

```{r scope-based, eval=FALSE}
# Parent logger
log_this <- logger() %>% with_receivers(to_console())

my_function <- function() {
  # Local enhancement - doesn't affect parent
  log_this <- log_this %>% with_receivers(to_text() %>% on_local("local.log"))
  log_this(NOTE("Only in this scope"))
}

my_function()
log_this(NOTE("Back to parent logger"))  # No file output
```

### 3. Formatter + Handler Pattern

Explicitly separate formatting from output destination:

```{r formatter-handler, eval=FALSE}
# Same format, different destinations
json_formatter <- to_json()

logger() %>%
  with_receivers(
    json_formatter %>% on_local("local.jsonl"),
    json_formatter %>% on_s3(bucket = "logs", key_prefix = "app"),
    json_formatter %>% on_azure(container = "logs", blob = "events.jsonl")
  )
```

### 4. Resilient Receiver Execution

Automatic failover with `purrr::safely()`:

```{r resilient, eval=FALSE}
# If one receiver fails, others continue
log_this <- logger() %>%
  with_receivers(
    to_console(),
    to_text() %>% on_local("/readonly/path.log"),  # May fail
    to_json() %>% on_s3(bucket = "logs")           # Still runs
  )

log_this(NOTE("Message"))
# Console and S3 receive message even if file write fails
```

### 5. Shiny Integration ⭐ MAJOR DIFFERENTIATOR

**No Python equivalent exists.** Python web frameworks (Dash, Streamlit, Flask) require custom JavaScript and callbacks for user notifications. logthis provides **built-in UI receivers** that automatically show alerts to Shiny users:

```{r shiny-integration, eval=FALSE}
library(shiny)
library(logthis)

# Setup logger with UI receivers
app_logger <- logger() %>%
  with_receivers(
    to_console(lower = NOTE),              # Developer console
    to_shinyalert(lower = ERROR),          # Modal alerts for errors
    to_notif(lower = WARNING, upper = WARNING),  # Toast notifications for warnings
    to_json() %>% on_local("app_audit.jsonl")    # Audit trail
  )

server <- function(input, output, session) {
  # Bind user context from Shiny session
  user_logger <- app_logger %>%
    with_tags(
      paste0("user:", session$user),
      paste0("session:", session$token)
    )

  observeEvent(input$process_data, {
    tryCatch({
      # Validation warnings automatically show as notifications
      if (nrow(input_data()) == 0) {
        user_logger(WARNING("No data to process"))
        return()
      }

      # Processing
      result <- process_data(input_data())

      # Success message
      user_logger(NOTE("Data processed successfully"))

    }, error = function(e) {
      # Errors automatically show as modal alerts + logged to file
      user_logger(ERROR(paste("Processing failed:", e$message)))
    })
  })
}
```

**Why this is a killer feature:**

| Feature | Python (Dash/Streamlit/Flask) | logthis + Shiny |
|---------|-------------------------------|-----------------|
| **User notifications** | Custom JavaScript/callbacks required | ✅ Built-in `to_shinyalert()`, `to_notif()` |
| **Session integration** | Manual context passing | ✅ Direct access to `session` object |
| **Audit + UI in one** | Separate systems (logging vs notifications) | ✅ Same logger for both audit trail and user alerts |
| **Level-based routing** | Manual if/else logic | ✅ Automatic (errors → modals, warnings → toasts) |
| **Lines of code** | 50+ lines for notification system | ✅ 3 lines (`to_shinyalert()` + `to_notif()`) |

**Real-world impact:**
- **Pharma clinical dashboards** - Medical monitors get instant alerts for serious AEs
- **Enterprise Shiny apps** - Users see friendly error messages while IT gets detailed logs
- **Data validation dashboards** - Warnings show as toasts, errors as blocking modals

### 6. Granular 0-100 Level Scale

More precise than traditional 5-level systems:

```{r granular-levels, eval=FALSE}
# Define custom levels at any point
BUSINESS <- log_event_level("BUSINESS", 50)  # Between MESSAGE and WARNING
AUDIT <- log_event_level("AUDIT", 35)        # Between NOTE and MESSAGE

log_this <- logger() %>%
  with_receivers(to_console()) %>%
  with_limits(lower = 30, upper = 70)  # Inclusive range

log_this(AUDIT("Audit event"))      # 35 - included
log_this(BUSINESS("KPI reached"))   # 50 - included
log_this(ERROR("Error"))            # 80 - excluded
```

## Design Philosophy Comparison

| Aspect | Python logging | loguru | structlog | logthis |
|--------|---------------|---------|-----------|---------|
| **Paradigm** | OOP, Imperative | Functional-lite | Pipeline | Pure Functional |
| **State Management** | Global registry | Global instance | Bound loggers | Explicit objects |
| **Configuration** | Dict/File | Method calls | Processors | Pipe composition |
| **Extensibility** | Subclass handlers | Custom sinks | Custom processors | Custom receivers/formatters |
| **Testing** | Mock/patch | Context manager | Test processors | Identity receiver |

## Migration Guide for Python Developers

### Conceptual Mapping

| Python Concept | logthis Equivalent | Notes |
|---------------|-------------------|-------|
| `logger.getLogger()` | `logger()` | Explicit object creation |
| Handler | Receiver | Determines output destination |
| Formatter | Formatter (to_text, to_json) | Defines output format |
| `logger.addHandler()` | `with_receivers()` | Pipe-based composition |
| `logger.setLevel()` | `with_limits()` | Logger-level filtering |
| Handler filter | Receiver `with_limits()` | Receiver-level filtering |
| `logger.bind()` (structlog) | `with_tags()` | Context/metadata binding |
| Sink (loguru) | Receiver | Output destination |

### Common Patterns

**Python namespace hierarchy:**
```python
logger = logging.getLogger("app.module.component")
```

**logthis scope-based approach:**
```{r scope-approach, eval=FALSE}
# Module-specific logger
module_logger <- logger() %>% with_tags("module:component")
```

**Python context manager:**
```python
with logger.contextualize(request_id=123):
    logger.info("Processing")
```

**logthis scope masking:**
```{r scope-masking, eval=FALSE}
process_request <- function(request_id) {
  log_this <- log_this %>% with_tags(paste0("request:", request_id))
  log_this(NOTE("Processing"))
}
```

## When to Choose Each Solution

### Choose Python `logging` when:
- Working with stdlib-only requirements
- Need hierarchical logger namespaces
- Integrating with Python frameworks (Django, Flask)
- Complex enterprise configurations via files

### Choose `loguru` when:
- Rapid prototyping in Python
- Want zero-config simplicity
- Need automatic log rotation
- Don't need multiple logger instances

### Choose `structlog` when:
- Structured JSON logging is critical
- Need to wrap/enhance existing loggers
- Building observability pipelines
- Working with log aggregation systems (ELK, Datadog)

### Choose `logthis` when:
- **Building Shiny applications** ⭐ (no Python equivalent for Dash/Streamlit)
- Working in R ecosystem
- **Need functional, composable design** (pure R idioms with pipes)
- Prefer explicit state over global configuration
- **Pharmaceutical/clinical analysis** (statistical provenance, regulatory submissions)
- Need scope-based logger enhancement
- Building R packages with logging
- Want resilient error handling (one receiver failure doesn't stop others)
- **Need cloud storage integration** (built-in S3/Azure receivers)

## Audit Logging in Production Systems

One of the most critical use cases for logging is **audit trails** - immutable records of who did what, when, and why. This is essential for:

- **Financial compliance** (SOX, PCI-DSS)
- **Healthcare** (HIPAA)
- **General data protection** (GDPR)
- **Forensics and security** investigations

### Python Audit Logging Approaches

#### 1. Django-Specific Solutions

**django-auditlog** - The most popular Django audit logging library:

```python
from auditlog.registry import auditlog
from django.db import models

class Transaction(models.Model):
    amount = models.DecimalField(max_digits=10, decimal_places=2)
    account = models.CharField(max_length=50)
    timestamp = models.DateTimeField(auto_now_add=True)

# Register for automatic audit logging
auditlog.register(Transaction)

# Every create/update/delete is automatically logged with:
# - User who made the change
# - Timestamp
# - Changes in JSON format
# - IP address (optional)
```

**django-simple-history** - Stores full model snapshots:

```python
from simple_history.models import HistoricalRecords

class Transaction(models.Model):
    amount = models.DecimalField(max_digits=10, decimal_places=2)
    history = HistoricalRecords()  # Automatically tracks all changes

# Query historical records
transaction.history.all()  # All versions
transaction.history.as_of('2024-01-01')  # State at specific time
```

#### 2. General Python Audit Logging Patterns

**Structured logging with context**:

```python
import structlog

logger = structlog.get_logger()

# Bind user context
logger = logger.bind(
    user_id=request.user.id,
    session_id=request.session.session_key,
    ip_address=request.META['REMOTE_ADDR']
)

# Log business events with full context
logger.info(
    "transaction_completed",
    transaction_id=txn.id,
    amount=float(txn.amount),
    account=txn.account,
    timestamp=txn.timestamp.isoformat()
)
```

**Python's built-in audit hooks** (Python 3.8+):

```python
import sys

def audit_hook(event, args):
    if event == 'open':
        filename, mode, flags = args
        log_security_event(f"File access: {filename} ({mode})")

sys.addaudithook(audit_hook)
```

### logthis Audit Logging Approach

logthis is uniquely suited for audit trails through its **tagging system** and **immutable event records**:

```{r audit-logging-logthis, eval=FALSE}
# Create audit logger with required fields
audit_log <- logger() %>%
  with_receivers(
    # Immutable append-only JSON log
    to_json() %>% on_local(
      path = "audit.jsonl",
      mode = "append"
    ),
    # Redundant cloud backup for compliance
    to_json() %>% on_s3(
      bucket = "compliance-logs",
      key_prefix = "audit/transactions"
    )
  ) %>%
  with_tags("audit", "financial")

# Log transaction with full context
process_transaction <- function(user_id, amount, account) {
  # Bind user context via tags
  txn_logger <- audit_log %>%
    with_tags(
      paste0("user:", user_id),
      paste0("session:", session$id),
      paste0("ip:", session$remote_addr)
    )

  # Log the transaction with structured fields
  txn_logger(NOTE(
    "transaction_completed",
    transaction_id = generate_id(),
    user_id = user_id,
    amount = amount,
    account = account,
    timestamp = Sys.time()
  ))

  # Transaction processing logic...
}
```

**JSONL output** (one line per transaction):

```json
{"time":"2024-10-08T10:30:45Z","level":"NOTE","level_number":30,"message":"transaction_completed","tags":["audit","financial","user:12345","session:abc123","ip:192.168.1.100"],"transaction_id":"txn_xyz","user_id":12345,"amount":1500.00,"account":"ACC-001","timestamp":"2024-10-08T10:30:45Z"}
```

### Audit Trail Best Practices: Python vs logthis

| Requirement | Python (django-auditlog) | Python (structlog) | logthis |
|-------------|-------------------------|-------------------|---------|
| **Immutable Records** | Database-backed | Append-only files | Append-only files + cloud |
| **Who** (Actor) | Automatic via middleware | Manual binding | Tags + custom fields |
| **What** (Action) | Model changes (JSON diff) | Custom event fields | Custom event fields |
| **When** (Timestamp) | Automatic | Automatic | Automatic |
| **Where** (Location) | IP via middleware | Manual binding | Tags |
| **Why** (Reason) | Optional change_reason field | Custom fields | Custom fields |
| **Context Binding** | Request-scoped | Logger.bind() | with_tags() |
| **Compliance Storage** | PostgreSQL WORM | ELK/Splunk/S3 | S3/Azure + local |

### Key Advantages of logthis for Audit Logging

1. **Tag-based context**: Hierarchical tags naturally represent user → session → transaction relationships

2. **Redundant storage**: Easy to send audit logs to multiple destinations simultaneously:
   ```r
   to_json() %>% on_local("audit.jsonl")  # Local compliance
   to_json() %>% on_s3(bucket = "audit")  # Cloud backup
   to_json() %>% on_azure(container = "audit")  # Multi-cloud redundancy
   ```

3. **Scope-based auditing**: Enable detailed logging only for sensitive operations:
   ```r
   process_sensitive_data <- function() {
     # Enhance audit logging in this scope only
     audit_log <- audit_log %>%
       with_tags("sensitive_data_access") %>%
       with_receivers(
         to_json() %>% on_local("sensitive_audit.jsonl")
       )

     # All logs in this scope get extra tracking
     audit_log(NOTE("data_accessed", record_id = 123))
   }
   ```

4. **Functional immutability**: Loggers are immutable; can't accidentally modify audit configuration

5. **Resilient receivers**: If one audit destination fails, others continue (critical for compliance)

### Compliance Considerations

**Both Python and logthis support:**
- Tamper-proof logs (append-only, WORM storage)
- Retention policies (archival to cold storage)
- Encryption in transit and at rest
- Centralized log aggregation
- Machine-readable structured formats (JSON)

**logthis advantages:**
- Simpler multi-cloud redundancy
- Built-in failover between audit destinations
- Tag-based provenance tracking (see [Tagging and Provenance](tagging-and-provenance.html))

**Python/Django advantages:**
- Deeper ORM integration (automatic model change tracking)
- Built-in admin interface for viewing audit logs
- Ecosystem of compliance-focused packages

## Pharmaceutical and Clinical Audit Trails

The pharmaceutical and clinical research industries have the most stringent audit trail requirements of any sector, driven by patient safety and regulatory compliance. **This section focuses on where R realistically fits in the pharma technology stack** - primarily in statistical analysis, data pipelines, and review dashboards, not primary data capture systems.

### Where R (and logthis) Actually Fits

**R's role in pharmaceutical workflows:**

```
Primary Systems          R Analysis Layer           Regulatory Outputs
----------------         ----------------           ------------------
CTMS/EDC databases  -->  R analysis scripts   -->  FDA eCTD submission
Safety databases    -->  Signal detection     -->  Safety reports
LIMS                -->  Biomarker analysis   -->  Publications
Registries          -->  Shiny dashboards     -->  Regulatory review
```

**logthis is designed for the middle layer** - auditing analysis provenance, data pipeline steps, and reviewer actions in R-based tools. It does NOT replace:
- Database audit logs (PostgreSQL, Oracle audit trails)
- Clinical Trial Management Systems (Medidata, Veeva)
- Manufacturing Execution Systems (Siemens, Rockwell)
- Electronic Health Records (Epic, Cerner)

### Regulatory Framework

When R-based systems are used in regulated workflows, they must comply with:

| Regulation | Scope | Key Requirements |
|------------|-------|------------------|
| **21 CFR Part 11** | FDA electronic records/signatures | Time-stamped audit trails, user attribution, change documentation |
| **EU Annex 11** | EU GMP computerized systems | Audit trail for changes, retention, availability for inspection |
| **GxP** (GCP/GLP/GMP) | Clinical/lab/manufacturing practices | Complete data lifecycle documentation |
| **ALCOA+ Principles** | Data integrity framework | Attributable, Legible, Contemporaneous, Original, Accurate + Complete, Consistent, Enduring, Available |
| **ICH Q10** | Pharmaceutical quality system | Risk-based approach to quality management |

### 21 CFR Part 11 Requirements

The FDA's 21 CFR Part 11 regulation establishes criteria for electronic records and signatures. The core audit trail requirements are:

1. **Secure, computer-generated, time-stamped audit trails** to independently record:
   - Date and time of operator entries
   - Actions that create, modify, or delete records

2. **Record changes must not obscure previously recorded information**

3. **Audit trail retention** for at least as long as the subject electronic records

4. **Available for agency review and copying**

### ALCOA+ Principles Mapping

logthis naturally aligns with ALCOA+ data integrity principles:

| Principle | Requirement | How logthis Addresses It |
|-----------|-------------|--------------------------|
| **Attributable** | Who performed the action? | User context via `with_tags()`, custom fields for user_id |
| **Legible** | Can the data be read? | Human-readable text + structured JSON formats |
| **Contemporaneous** | Recorded when it happened? | Automatic timestamp in every event |
| **Original** | First recorded data | Append-only files, immutable event objects |
| **Accurate** | Free from errors | Type-safe event construction, validated receivers |
| **Complete** | All required data present | Mandatory fields (time, level, message) + custom fields |
| **Consistent** | Chronological sequence | Time-ordered events, sequential file writes |
| **Enduring** | Durable storage | Cloud redundancy (S3/Azure), local archival |
| **Available** | Retrievable when needed | Queryable JSON/Parquet formats, cloud accessibility |

### Realistic Pharmaceutical Use Cases

#### 1. Statistical Analysis Provenance for Regulatory Submissions

**THE primary use case:** Document who ran what analysis, when, with what parameters for FDA/EMA submissions.

```{r analysis-provenance, eval=FALSE}
# Analysis audit logger for regulatory submission
analysis_audit <- logger() %>%
  with_receivers(
    # Local JSONL for submission package
    to_json() %>% on_local(
      path = "outputs/analysis_audit.jsonl",
      mode = "append"
    ),
    # Cloud backup for sponsor archive
    to_json() %>% on_s3(
      bucket = "regulatory-submissions",
      key_prefix = "NCT12345678/analysis_logs"
    )
  ) %>%
  with_tags("trial:NCT12345678", "submission:NDA_2024") %>%
  with_limits(lower = NOTE)

# Audit primary efficacy analysis
run_primary_efficacy_analysis <- function() {
  # Log analysis start with full provenance
  analysis_audit(NOTE(
    "primary_efficacy_analysis_started",
    analyst_id = Sys.getenv("USER"),
    analyst_name = "Jane Statistician, PhD",
    analysis_plan_version = "SAP_v3.0_final",
    population = "ITT",  # Intent-to-treat
    endpoint = "change_from_baseline_week_12",
    input_dataset = "adeff.sas7bdat",
    input_dataset_hash = digest::digest(file = "data/adeff.sas7bdat"),
    input_n_subjects = 450,
    r_version = as.character(getRversion()),
    script_path = "programs/efficacy_primary.R",
    git_commit = system("git rev-parse HEAD", intern = TRUE)
  ))

  # Run the analysis
  results <- lm(change ~ treatment + baseline, data = efficacy_data)

  # Log analysis completion
  analysis_audit(NOTE(
    "primary_efficacy_analysis_completed",
    p_value = summary(results)$coefficients["treatmentActive", "Pr(>|t|)"],
    treatment_effect = coef(results)["treatmentActive"],
    confidence_interval = paste(confint(results)["treatmentActive", ], collapse = ", "),
    output_tables = c("table_14_2_1.rtf", "table_14_2_2.rtf"),
    output_figures = c("figure_14_2_1.png"),
    analysis_duration_seconds = elapsed
  ))

  return(results)
}
```

**Why this matters for regulatory inspection:**
- ✅ Proves analysis wasn't cherry-picked (git commit hash)
- ✅ Documents input data integrity (file hash)
- ✅ Traces output tables to analysis script
- ✅ Shows analysis plan version used
- ✅ Provides audit trail for FDA/EMA reviewers

#### 2. Shiny Clinical Review Dashboard Audit

**Common real use case:** Track medical monitor actions in Shiny dashboards for data review.

```{r shiny-dashboard-audit, eval=FALSE}
library(shiny)
library(logthis)

# Dashboard audit logger
dashboard_audit <- logger() %>%
  with_receivers(
    to_json() %>% on_local(
      path = "dashboard_audit.jsonl",
      mode = "append"
    ),
    to_json() %>% on_s3(
      bucket = "clinical-monitoring",
      key_prefix = "trial_NCT123/dashboard_audit"
    )
  ) %>%
  with_tags("app:adverse_event_review", "trial:NCT123")

# Shiny server with audit logging
server <- function(input, output, session) {
  # Get user context from Shiny session
  user_audit <- dashboard_audit %>%
    with_tags(
      paste0("user:", session$user),
      paste0("session:", session$token)
    )

  # Log when user views an adverse event
  observeEvent(input$ae_table_rows_selected, {
    ae_id <- ae_data[input$ae_table_rows_selected, "ae_id"]

    user_audit(NOTE(
      "ae_record_viewed",
      ae_id = ae_id,
      user_id = session$user,
      user_role = get_user_role(session$user),
      view_timestamp = Sys.time()
    ))
  })

  # Log when user flags a serious adverse event
  observeEvent(input$btn_flag_serious, {
    user_audit(WARNING(
      "ae_flagged_as_serious",
      ae_id = input$selected_ae_id,
      user_id = session$user,
      flagging_reason = input$serious_ae_reason,
      requires_expedited_reporting = TRUE,
      medical_monitor_notified = TRUE
    ))

    # Trigger notification workflow
    notify_medical_monitor(input$selected_ae_id)
  })

  # Log data export actions (for audit trail)
  observeEvent(input$btn_export_data, {
    user_audit(NOTE(
      "data_exported",
      user_id = session$user,
      export_type = input$export_format,  # CSV, PDF, etc.
      filters_applied = list(
        severity = input$filter_severity,
        date_range = input$filter_dates
      ),
      records_exported = nrow(filtered_data())
    ))
  })
}
```

**Why this matters:**
- ✅ Documents who reviewed which AEs (required for medical monitoring)
- ✅ Tracks critical decisions (flagging serious AEs)
- ✅ Audit trail for data exports
- ✅ Supports regulatory inspection of review process

#### 3. Safety Signal Detection Pipeline

**Realistic use case:** Audit automated safety monitoring scripts that detect signals from safety databases.

```{r safety-signal-audit, eval=FALSE}
# Safety signal detection audit logger
signal_audit <- logger() %>%
  with_receivers(
    to_json() %>% on_local(
      path = "safety_monitoring/signal_detection_audit.jsonl",
      mode = "append"
    ),
    to_json() %>% on_s3(
      bucket = "pharmacovigilance",
      key_prefix = "signal_detection_logs"
    ),
    # Alert safety team if potential signal detected
    to_console(lower = WARNING)
  ) %>%
  with_tags("drug:XYZ123", "monitoring:weekly_signal_detection")

# Automated weekly safety signal detection
run_weekly_signal_detection <- function() {
  # Log analysis start
  signal_audit(NOTE(
    "signal_detection_analysis_started",
    analysis_type = "disproportionality_analysis",
    data_cutoff_date = Sys.Date(),
    method = "bayesian_confidence_propagation",
    threshold_ic025 = 0,  # Information Component lower bound
    analyst = "automated_pipeline"
  ))

  # Query safety database (primary AE data is THERE, not in R)
  ae_data <- DBI::dbGetQuery(safety_db, "
    SELECT ae_term, count(*) as n_reports
    FROM adverse_events
    WHERE drug_exposure = 'XYZ123'
      AND report_date >= CURRENT_DATE - INTERVAL '90 days'
    GROUP BY ae_term
  ")

  # Run signal detection algorithm
  signals <- detect_disproportionality(ae_data, method = "bcpnn")

  # Log any potential signals detected
  for (i in seq_len(nrow(signals))) {
    if (signals$ic025[i] > 0) {  # Potential signal threshold
      signal_audit(WARNING(
        "potential_safety_signal_detected",
        ae_term = signals$ae_term[i],
        ic025 = signals$ic025[i],
        n_reports = signals$n_reports[i],
        reporting_rate = signals$reporting_rate[i],
        recommendation = "Manual review by safety physician required",
        priority = ifelse(signals$ic025[i] > 2, "high", "medium")
      ))
    }
  }

  # Log completion
  signal_audit(NOTE(
    "signal_detection_analysis_completed",
    total_ae_terms_analyzed = nrow(ae_data),
    signals_detected = sum(signals$ic025 > 0),
    high_priority_signals = sum(signals$ic025 > 2),
    next_review_date = Sys.Date() + 7
  ))
}
```

**Why this matters:**
- ✅ Documents safety monitoring was performed (regulatory requirement)
- ✅ Creates audit trail of signal detection runs
- ✅ Alerts safety team to potential issues
- ✅ Separates primary AE data (in database) from analysis (in R)

### Validation and CSV (Computer System Validation)

For FDA-regulated systems, computer system validation (CSV) is required. logthis supports validation through:

1. **Deterministic behavior**: Pure functions with no hidden state
2. **Test coverage**: 84%+ coverage with 130+ passing tests demonstrates quality
3. **Version control**: All code changes tracked in git
4. **Documentation**: Comprehensive roxygen2 documentation for traceability
5. **Change control**: Semantic versioning and NEWS.md change log

**Validation documentation workflow:**

```{r validation-workflow, eval=FALSE}
# Create validation logger for CSV lifecycle
validation_log <- logger() %>%
  with_receivers(
    to_text() %>% on_local(
      path = "/validation/logthis_v0.1.0/validation_log.txt"
    ),
    to_json() %>% on_local(
      path = "/validation/logthis_v0.1.0/validation_log.jsonl",
      mode = "append"
    )
  ) %>%
  with_tags("system:logthis", "version:0.1.0", "validation_phase:IQ_OQ_PQ")

# Installation Qualification (IQ)
validation_log(NOTE(
  "installation_qualification_passed",
  test_type = "IQ",
  r_version = as.character(getRversion()),
  package_version = packageVersion("logthis"),
  dependencies_validated = TRUE,
  installation_path = .libPaths()[1]
))

# Operational Qualification (OQ)
validation_log(NOTE(
  "operational_qualification_passed",
  test_type = "OQ",
  test_cases_executed = 130,
  test_cases_passed = 130,
  test_coverage_percent = 84.3,
  test_report_path = "tests/testthat/test-results.xml"
))

# Performance Qualification (PQ)
validation_log(NOTE(
  "performance_qualification_passed",
  test_type = "PQ",
  scenario = "clinical_trial_audit_logging",
  events_logged_per_second = 1000,
  storage_backends_tested = c("local", "s3", "azure"),
  failover_tested = TRUE,
  acceptance_criteria_met = TRUE
))
```

### Best Practices for Pharma Audit Trails

1. **Always use append-only mode** for audit logs:
   ```r
   to_json() %>% on_local(path = "audit.jsonl", mode = "append")  # CORRECT
   # Never use mode = "overwrite" for audit logs!
   ```

2. **Implement redundant storage** for critical audit trails:
   ```r
   logger() %>%
     with_receivers(
       to_json() %>% on_local("/primary/audit.jsonl"),   # Primary
       to_json() %>% on_s3(bucket = "backup"),            # Cloud backup
       to_json() %>% on_azure(container = "audit")        # Geo-redundant
     )
   ```

3. **Use tags for hierarchical context** (trial → site → patient → session):
   ```r
   clinical_audit %>%
     with_tags("trial:NCT123") %>%
     with_tags("site:001") %>%
     with_tags("patient:P456") %>%
     with_tags(paste0("session:", session_id))
   ```

4. **Include electronic signatures** for 21 CFR Part 11 Part B compliance:
   ```r
   log_this(NOTE(
     "critical_action_performed",
     electronic_signature = list(
       user_id = user_id,
       signature_hash = digest::digest(paste0(user_id, timestamp, secret)),
       signature_meaning = "I certify this action was performed correctly",
       timestamp_utc = timestamp
     )
   ))
   ```

5. **Validate storage destinations** before production use:
   ```r
   # Test audit logger before going live
   test_audit_logger <- function(audit_logger) {
     # Send test event
     test_event <- audit_logger(NOTE("validation_test_event", test_id = uuid()))

     # Verify event written to all receivers
     stopifnot(file.exists("/primary/audit.jsonl"))
     stopifnot(s3_object_exists("backup/audit.jsonl"))

     # Verify event integrity
     logged_event <- jsonlite::read_json("/primary/audit.jsonl", n = 1)
     stopifnot(logged_event$message == "validation_test_event")
   }
   ```

### Comparison with Python Pharma Tools

**Where each tool fits in the pharma stack:**

| System Layer | Python Tools | logthis | Winner |
|--------------|--------------|---------|--------|
| **Primary Data Capture** | Django CTMS, Flask apps with audit | ❌ Not applicable | Python (R not used here) |
| **Database Audit Logs** | PostgreSQL triggers, SQLAlchemy events | ❌ Not applicable | Database native features |
| **Statistical Analysis Provenance** | Limited (notebooks, papermill) | ✅ **Native R audit logging** | **logthis** (R-first design) |
| **Shiny Dashboards** | Limited (Python Dash with custom logging) | ✅ **Built-in Shiny integration** | **logthis** |
| **Batch Data Pipelines** | Airflow + structlog | ✅ R script audit trails | Both good (different ecosystems) |
| **Multi-cloud Storage** | Custom S3/Azure wrappers | ✅ Built-in receivers | **logthis** (simpler) |

**Honest assessment - When to use logthis:**
- ✅ **Statistical analysis for regulatory submissions** (THE killer use case)
- ✅ **Shiny clinical review dashboards** (common in pharma)
- ✅ **R-based safety monitoring pipelines**
- ✅ **Data pipeline audit trails** (ETL from DB → R → submission)
- ✅ **Automated report generation** (who ran what, when)

**When logthis does NOT fit:**
- ❌ Primary clinical trial data entry (use CTMS like Medidata/Veeva)
- ❌ Manufacturing execution systems (use MES like Siemens/Rockwell)
- ❌ Electronic health records (use Epic/Cerner audit trails)
- ❌ Database-level access control (use PostgreSQL/Oracle audit features)

## Performance Considerations

### Python Solutions

- **logging**: Good performance, but can be slow with many handlers
- **loguru**: Slightly slower than stdlib due to features, but negligible for most use cases
- **structlog**: Performance depends on processor chain length

### logthis

- **Functional composition**: No global state lookup overhead
- **Resilient receivers**: `purrr::safely()` wrapper adds minimal overhead
- **Lazy evaluation**: R's lazy evaluation can optimize pipe chains
- **Cloud receivers**: Buffering reduces network overhead

Benchmark vignette available separately for detailed performance analysis.

## Conclusion

**logthis brings Python-level logging maturity to R** with a uniquely R-flavored design:

- **Conceptual Familiarity**: Similar to Python's `logging` module architecture
- **Modern Simplicity**: Inspired by loguru's ease of use
- **Structured Output**: Like structlog's JSON-first approach
- **R Idioms**: Leverages pipes, functional composition, and lexical scoping

Whether you're migrating from Python or building R applications from scratch, logthis provides a powerful, flexible logging framework that feels natural in R while offering capabilities comparable to Python's mature ecosystem.

## Further Reading

- [Getting Started](getting-started.html) - Quick introduction to logthis
- [Advanced Receivers](advanced-receivers.html) - Cloud storage, webhooks, and custom receivers
- [Patterns](patterns.html) - Common logging patterns and best practices
- [Tagging and Provenance](tagging-and-provenance.html) - Using tags for context and audit trails

## References

- [Python logging documentation](https://docs.python.org/3/library/logging.html)
- [loguru GitHub repository](https://github.com/Delgan/loguru)
- [structlog documentation](https://www.structlog.org/)
- [Logging in Python: A Comparison](https://betterstack.com/community/guides/logging/best-python-logging-libraries/)
