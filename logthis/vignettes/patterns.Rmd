---
title: "Common Patterns and Recipes"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Common Patterns and Recipes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(logthis)
```

This vignette catalogs common logging patterns with the `logthis` package. Each pattern is tagged for easy search and reference.

---

## Pattern: Basic Logging
**Tags**: `#basic`, `#console`, `#getting-started`

Create a logger and log to console.

```{r eval=FALSE}
log_this <- logger() %>%
  with_receivers(to_console())

log_this(NOTE("Application started"))
log_this(ERROR("Something failed"))
```

**When to use**: Development, debugging, simple applications.

---

## Pattern: Multi-Destination Logging
**Tags**: `#multi-destination`, `#console`, `#file`, `#s3`, `#azure`

Log to multiple destinations simultaneously.

```{r eval=FALSE}
log_this <- logger() %>%
  with_receivers(
    to_console(),                    # For development visibility
    to_text() %>% on_local(path = "app.log"),  # For local debugging
    to_json() %>%                    # For production analytics
      on_s3(bucket = "logs",
            key = "prod/app.jsonl")
  )

log_this(ERROR("Database timeout", query = "SELECT ...", duration_ms = 5000))
# → Appears in console, app.log, and S3
```

**When to use**: Production applications, when different consumers need different formats.

---

## Pattern: Tiered Filtering
**Tags**: `#filtering`, `#levels`, `#performance`

Different log levels for different receivers.

```{r eval=FALSE}
log_this <- logger() %>%
  with_receivers(
    to_console(lower = ERROR),       # Console: errors only
    to_text() %>% on_local(path = "debug.log"),  # File: everything
    to_json() %>%                    # S3: warnings and above
      on_s3(bucket = "logs",
            key = "warnings.jsonl",
            lower = WARNING)
  )

log_this(DEBUG("Detailed info"))     # Only in debug.log
log_this(WARNING("Heads up"))        # debug.log + S3
log_this(ERROR("Failed"))            # All three destinations
```

**When to use**: Reduce noise in console, balance detail vs. cost, optimize performance.

---

## Pattern: File Rotation
**Tags**: `#file`, `#rotation`, `#disk-management`

Automatically rotate log files when they reach size limit.

```{r eval=FALSE}
log_this <- logger() %>%
  with_receivers(
    to_text() %>% on_local(path = "app.log",
                           max_size = 10485760,    # 10 MB
                           max_files = 5)  # Keep 5 rotations
  )

# When app.log reaches 10MB:
# app.log.4 → deleted
# app.log.3 → app.log.4
# app.log.2 → app.log.3
# app.log.1 → app.log.2
# app.log   → app.log.1
# (new)     → app.log
```

**When to use**: Long-running applications, disk space constraints.

---

## Pattern: Tagged Events
**Tags**: `#tagging`, `#categorization`, `#filtering`

Add tags for categorization and filtering.

```{r eval=FALSE}
# Global tags (applied to all events)
log_this <- logger() %>%
  with_receivers(to_json() %>% on_local(path = "events.jsonl")) %>%
  with_tags("api", "production", "v2")

# Per-event tags
log_this(NOTE("Request received",
              tags = c("auth", "success")))
# → Event has tags: ["api", "production", "v2", "auth", "success"]

# Use tags in templates
log_this <- logger() %>%
  with_receivers(
    to_text("{time} {tags} [{level}] {message}") %>%
      on_local("tagged.log")
  )
```

**When to use**: Categorize events, filter logs downstream, trace request flows.

---

## Pattern: Custom Fields
**Tags**: `#custom-fields`, `#context`, `#structured`

Add arbitrary context to events.

```{r eval=FALSE}
log_this <- logger() %>%
  with_receivers(to_json() %>% on_local(path = "events.jsonl"))

log_this(ERROR("Payment failed",
               user_id = 12345,
               transaction_id = "txn_abc",
               amount = 99.99,
               payment_method = "visa"))

# JSON output includes all fields:
# {
#   "time": "2025-10-07T10:23:45",
#   "level": "ERROR",
#   "message": "Payment failed",
#   "user_id": 12345,
#   "transaction_id": "txn_abc",
#   ...
# }
```

**When to use**: Structured logging, event analytics, debugging complex systems.

---

## Pattern: Custom Template
**Tags**: `#formatting`, `#template`, `#customization`

Define custom text format with template variables.

```{r eval=FALSE}
log_this <- logger() %>%
  with_receivers(
    to_text("{time} | {level}:{level_number} | {message}") %>%
      on_local("custom.log")
  )

log_this(NOTE("Custom format"))
# Output: 2025-10-07 10:23:45 | NOTE:30 | Custom format

# Include custom fields
log_this <- logger() %>%
  with_receivers(
    to_text("{time} [{level}] {message} | User: {user_id}") %>%
      on_local("app.log")
  )

log_this(NOTE("Action performed", user_id = 456))
# Output: 2025-10-07 10:23:45 [NOTE] Action performed | User: 456
```

**When to use**: Legacy log format compatibility, specific parsing requirements.

---

## Pattern: Scope-Based Enhancement
**Tags**: `#scope`, `#immutability`, `#enhancement`

Add logging for specific function without modifying base logger.

```{r eval=FALSE}
# Shared base logger
.base_logger <- logger() %>%
  with_receivers(to_console())

# Function-specific enhanced logger
process_data <- function(data) {
  log_this <- .base_logger %>%
    with_receivers(to_text() %>% on_local(path = "process_data_detail.log")) %>%
    with_tags("process_data")

  log_this(NOTE("Processing started", rows = nrow(data)))
  # ... processing logic ...
  log_this(NOTE("Processing complete"))

  data
}

# Base logger unchanged, enhancement scoped to function
```

**When to use**: Add detail for specific subsystems, maintain clean base logger.

---

## Pattern: Custom Helper Functions
**Tags**: `#helpers`, `#custom`, `#syntactic-sugar`, `#scope-based`

Create your own helper functions for cleaner tagging syntax.

```{r eval=FALSE}
# Define custom helpers for your naming conventions

# Example 1: Component context helper
at_component <- function(logger, ...) {
  logger %>% with_tags(...)
}

# Example 2: User context helper
for_user <- function(logger, user_id, session_id = NULL) {
  tags <- list(user_id = user_id)
  if (!is.null(session_id)) tags$session_id <- session_id
  do.call(with_tags, c(list(logger), tags))
}

# Example 3: Request context helper
for_request <- function(logger, request_id, ...) {
  logger %>% with_tags(request_id = request_id, ...)
}

# Use your custom helpers
db_query <- function(sql) {
  log_this <- logger() %>%
    with_receivers(to_console()) %>%
    at_component(component = "database", operation = "query")

  log_this(NOTE("Executing query", sql = sql))
}

# In Shiny server
server <- function(input, output, session) {
  log_this <- logger() %>%
    with_receivers(to_console()) %>%
    for_user(user_id = session$user, session_id = session$token)

  observeEvent(input$submit, {
    log_this(NOTE("Form submitted"))  # Auto-tagged with user info
  })
}

# In API endpoint
api_handler <- function(req, res) {
  log_this <- logger() %>%
    with_receivers(to_console()) %>%
    for_request(request_id = req$id, method = req$REQUEST_METHOD)

  log_this(NOTE("Processing request"))
}
```

**When to use**: Establish team-wide naming conventions, create domain-specific logging DSL, reduce boilerplate.

**Note**: `logthis` intentionally keeps core API minimal - `with_tags()` is the primitive. Build helpers that match your domain and team preferences.

---

## Pattern: Environment-Based Configuration
**Tags**: `#environment`, `#configuration`, `#switch-statement`, `#scope-based`

Configure loggers differently based on environment (development, staging, production).

```{r eval=FALSE}
# Pattern: Switch on environment variable
setup_logger <- function(env = Sys.getenv("ENV", "development")) {
  env <- tolower(env)

  # Start with base logger + environment tag
  log_this <- logger() %>%
    with_tags(environment = env)

  # Configure based on environment
  if (env == "development") {
    # Verbose: TRACE level, console only
    log_this <- log_this %>%
      with_receivers(to_console(lower = TRACE)) %>%
      with_limits(lower = TRACE)

  } else if (env == "staging") {
    # Moderate: NOTE level, console + file
    log_this <- log_this %>%
      with_receivers(
        to_console(lower = NOTE),
        to_json() %>% on_local("staging.jsonl")
      ) %>%
      with_limits(lower = NOTE)

  } else if (env == "production") {
    # Minimal console, full audit trail to cloud
    log_this <- log_this %>%
      with_receivers(
        to_console(lower = WARNING),
        to_json() %>%
          on_s3(bucket = "prod-logs",
                key = "app.jsonl",
                region = "us-east-1")
      ) %>%
      with_limits(lower = NOTE)
  }

  log_this
}

# Use in application
main <- function() {
  log_this <- setup_logger()

  log_this(DEBUG("Detailed info"))      # Only in dev
  log_this(NOTE("Processing started"))  # All environments
  log_this(WARNING("Issue detected"))   # All environments
}

# Or use directly in functions
process_data <- function(data) {
  log_this <- setup_logger() %>%
    with_tags(component = "data_processing")

  log_this(NOTE("Processing", rows = nrow(data)))
  # ...
}
```

**Advanced: GxP-compliant environments**

```{r eval=FALSE}
setup_gxp_logger <- function(env = Sys.getenv("ENV", "development"),
                              study_id = NULL) {
  env <- tolower(env)

  log_this <- logger() %>%
    with_tags(environment = env)

  # Add study ID for GxP workflows
  if (!is.null(study_id)) {
    log_this <- log_this %>% with_tags(study_id = study_id)
  }

  if (env == "development") {
    log_this <- log_this %>%
      with_receivers(to_console(lower = DEBUG)) %>%
      with_limits(lower = DEBUG)

  } else if (env == "validation") {
    # Validation environment: full audit to immutable storage
    log_this <- log_this %>%
      with_receivers(
        to_console(lower = NOTE),
        to_json() %>%
          on_s3(bucket = "validation-logs",
                key = paste0(study_id, "/validation.jsonl"))
      ) %>%
      with_limits(lower = DEBUG)  # Capture everything

  } else if (env == "production") {
    # Production: WORM storage, alerts for errors
    log_this <- log_this %>%
      with_receivers(
        to_console(lower = WARNING),
        to_json() %>%
          on_s3(bucket = "gxp-audit-trail",
                key = paste0(study_id, "/", Sys.Date(), ".jsonl")),
        to_email(
          to = "quality@pharma.com",
          subject = paste("GxP Alert:", study_id)
        ) %>% with_limits(lower = ERROR)
      ) %>%
      with_limits(lower = NOTE)
  }

  log_this
}

# Usage in clinical workflow
analyze_trial_data <- function(data, study_id) {
  log_this <- setup_gxp_logger(study_id = study_id) %>%
    with_tags(component = "statistical_analysis")

  log_this(NOTE("Analysis started",
                study_id = study_id,
                analyst = Sys.getenv("USER"),
                timestamp = Sys.time()))

  # ... analysis ...

  log_this(NOTE("Analysis complete",
                n_subjects = nrow(data),
                analysis_duration_sec = duration))
}
```

**When to use**: Multi-environment deployments, centralized configuration, GxP compliance, different logging strategies per environment.

**Key benefit**: Users control their own configuration logic - no hardcoded paths or assumptions from the package.

---

## Pattern: Pipeline Logging with Tidylog
**Tags**: `#pipeline`, `#tidylog`, `#dplyr`, `#audit-trail`

Automatically log all dplyr/tidyr transformations using tidylog integration.

```{r eval=FALSE}
library(dplyr)
library(tidylog)

# Pattern: Basic pipeline logger
setup_pipeline_logger <- function(pipeline_name, audit_path) {
  log_this <- logger() %>%
    with_tags(
      pipeline_name = pipeline_name,
      logging_type = "pipeline"
    ) %>%
    with_receivers(
      to_json() %>% on_local(path = audit_path),
      to_console(lower = NOTE)
    )

  # Enable tidylog integration
  log_tidyverse(logger = log_this, pipeline_id = pipeline_name)

  # Log initialization
  log_this(NOTE("Pipeline logger initialized",
                pipeline_name = pipeline_name,
                audit_path = audit_path))

  log_this
}

# Use in pipeline
derive_analysis_data <- function(raw_data) {
  log_this <- setup_pipeline_logger(
    pipeline_name = "derive_analysis",
    audit_path = "pipeline_audit.jsonl"
  )

  # All dplyr operations are automatically logged
  analysis_data <- raw_data %>%
    filter(!is.na(USUBJID)) %>%          # Logged: "filter: removed X rows"
    mutate(AGE = as.numeric(AGE)) %>%    # Logged: "mutate: converted X values"
    select(USUBJID, AGE, SEX, RACE)      # Logged: "select: dropped X columns"

  log_this(NOTE("Pipeline complete",
                output_rows = nrow(analysis_data)))

  analysis_data
}
```

**Advanced: Manual pipeline logging**

```{r eval=FALSE}
# For more control, log manually in pipelines
log_this <- logger() %>% with_receivers(to_console())

result <- iris %>%
  filter(Species == "setosa") %>%
  log_this(NOTE("Filtered to setosa")) %>%
  mutate(petal_ratio = Petal.Length / Petal.Width) %>%
  log_this(NOTE("Calculated ratios")) %>%
  arrange(desc(petal_ratio))

# Logger returns data unchanged, pipeline continues seamlessly
```

**When to use**: Data pipeline audit trails, dplyr/tidyr transformations, clinical data derivations, reproducibility tracking.

---

## Pattern: Conditional Logging
**Tags**: `#conditional`, `#performance`, `#optimization`

Skip expensive logging when level is filtered.

```{r eval=FALSE}
log_this <- logger() %>%
  with_receivers(to_console()) %>%
  with_limits(lower = WARNING, upper = HIGHEST)

# Bad: Always computes expensive_data even if filtered
log_this(DEBUG("Debug info", data = compute_expensive_data()))

# Good: Check filter first
if (as.numeric(attr(log_this, "config")$limits$lower) <= 20) {
  log_this(DEBUG("Debug info", data = compute_expensive_data()))
}
```

**When to use**: High-volume logging, expensive serialization, performance-critical paths.

---

## Pattern: Error Handling
**Tags**: `#errors`, `#resilience`, `#graceful-degradation`

Logger continues despite receiver failures (built-in).

```{r eval=FALSE}
failing_receiver <- receiver(function(event) {
  stop("Simulated failure")
})

log_this <- logger() %>%
  with_receivers(
    to_console(),
    failing_receiver(),
    to_text() %>% on_local(path = "app.log")
  )

log_this(NOTE("Test message"))
# → Appears in console and app.log
# → Error logged: "[ERROR] Receiver #2 failed: Simulated failure"
```

**When to use**: Always! This is built-in behavior ensuring reliability.

---

## Pattern: Custom Log Level
**Tags**: `#custom-level`, `#audit`, `#domain-specific`

Create application-specific log levels.

```{r eval=FALSE}
# Define between existing levels based on severity
AUDIT <- log_event_level("AUDIT", 35)  # Between NOTE(30) and MESSAGE(40)

log_this <- logger() %>%
  with_receivers(to_text() %>% on_local(path = "audit.log"))

log_this(AUDIT("User accessed sensitive data",
               user_id = 789,
               resource = "customer_pii",
               action = "read"))
```

**When to use**: Compliance logging, business events, domain-specific severity.

---

## Pattern: Production vs. Development
**Tags**: `#environment`, `#production`, `#development`, `#configuration`

Different logging for different environments.

```{r eval=FALSE}
if (Sys.getenv("ENVIRONMENT") == "production") {
  log_this <- logger() %>%
    with_receivers(
      to_json() %>%
        on_s3(bucket = "prod-logs",
              key = "app.jsonl",
              region = "us-east-1")
    ) %>%
    with_limits(lower = WARNING)
} else {
  log_this <- logger() %>%
    with_receivers(
      to_console(),
      to_text() %>% on_local(path = "debug.log")
    ) %>%
    with_limits(lower = DEBUG)
}
```

**When to use**: Environment-specific behavior, reduce production noise, local debugging.

---

## Pattern: Disable Logging (Performance)
**Tags**: `#performance`, `#production`, `#optimization`, `#void`

Zero-overhead logging for production.

```{r eval=FALSE}
if (Sys.getenv("ENABLE_LOGGING") == "false") {
  log_this <- void_logger()
} else {
  log_this <- logger() %>%
    with_receivers(to_console())
}

# Logging calls have no effect with void_logger()
log_this(TRACE("Very verbose"))
log_this(DEBUG("Debug info"))
```

**When to use**: Performance-critical production systems, A/B testing logging overhead.

---

## Pattern: Config-Driven Setup
**Tags**: `#configuration`, `#config-package`, `#yaml`, `#environments`

Configure logging via YAML (using `config` package).

```{r eval=FALSE}
# config.yml
# default:
#   logging:
#     min_level: DEBUG
#     receivers:
#       - console: true
#       - file:
#           path: "app.log"
# production:
#   logging:
#     min_level: WARNING
#     receivers:
#       - s3:
#           bucket: "prod-logs"
#           key: "app.jsonl"

setup_logger_from_config <- function() {
  cfg <- config::get()

  log <- logger()
  receivers <- list()

  for (recv_cfg in cfg$logging$receivers) {
    if (!is.null(recv_cfg$console)) {
      receivers <- c(receivers, list(to_console()))
    }
    if (!is.null(recv_cfg$file)) {
      receivers <- c(receivers, list(to_text() %>% on_local(path = recv_cfg$file$path)))
    }
    if (!is.null(recv_cfg$s3)) {
      receivers <- c(receivers,
                     list(to_json() %>%
                            on_s3(bucket = recv_cfg$s3$bucket,
                                  key = recv_cfg$s3$key)))
    }
  }

  log %>%
    with_receivers(!!!receivers) %>%
    with_limits(lower = get(cfg$logging$min_level))
}

log_this <- setup_logger_from_config()
```

**When to use**: Multi-environment deployments, centralized configuration, team standards.

---

## Pattern: Batch Processing with Checkpoints
**Tags**: `#batch`, `#checkpoint`, `#progress`, `#long-running`

Log progress in batch jobs.

```{r eval=FALSE}
log_this <- logger() %>%
  with_receivers(
    to_console(),
    to_json() %>% on_local(path = "batch_progress.jsonl")
  )

process_batch <- function(items) {
  total <- length(items)
  log_this(NOTE("Batch started", total_items = total))

  for (i in seq_along(items)) {
    # Process item
    result <- process_item(items[[i]])

    # Log every 100 items
    if (i %% 100 == 0) {
      log_this(NOTE("Progress checkpoint",
                    processed = i,
                    total = total,
                    percent = round(i / total * 100, 1)))
    }

    # Log errors
    if (is.error(result)) {
      log_this(ERROR("Item processing failed",
                     item_id = items[[i]]$id,
                     error = result$message))
    }
  }

  log_this(NOTE("Batch complete", total_items = total))
}
```

**When to use**: Long-running jobs, progress monitoring, resumable processing.

---

## Pattern: Request Tracing
**Tags**: `#tracing`, `#request-id`, `#distributed`, `#tags`

Trace requests through system with request ID.

```{r eval=FALSE}
handle_request <- function(request) {
  request_id <- request$headers$`X-Request-ID` %||% generate_id()

  # Create request-specific logger
  req_log <- logger() %>%
    with_receivers(
      to_console(),
      to_json() %>%
        on_s3(bucket = "request-logs",
              key = paste0("requests/", Sys.Date(), ".jsonl"))
    ) %>%
    with_tags("api", request_id)

  req_log(NOTE("Request received",
               method = request$method,
               path = request$path))

  # Pass logger to downstream functions
  result <- process_request(request, req_log)

  req_log(NOTE("Request complete",
               status = result$status,
               duration_ms = result$duration))

  result
}

# All events for this request have the request_id tag
```

**When to use**: APIs, microservices, distributed tracing, request debugging.

---

## Pattern: Security Event Logging
**Tags**: `#security`, `#audit`, `#compliance`, `#custom-level`

Specialized logging for security events.

```{r eval=FALSE}
# Define security levels
SEC_INFO <- log_event_level("SEC_INFO", 45)
SEC_ALERT <- log_event_level("SEC_ALERT", 70)
SEC_BREACH <- log_event_level("SEC_BREACH", 95)

sec_logger <- logger() %>%
  with_receivers(
    # Console: Alerts and breaches only
    to_console(lower = SEC_ALERT),

    # Secure file: All security events
    to_json() %>% on_local(path = "security.jsonl") %>% with_limits(lower = SEC_INFO),

    # Immutable archive: Breaches only
    to_json() %>%
      on_s3(bucket = "security-archive",
            key = "breaches.jsonl",
            lower = SEC_BREACH)
  ) %>%
  with_tags("security")

# Usage
sec_logger(SEC_INFO("Login attempt", user_id = 123, success = TRUE))
sec_logger(SEC_ALERT("Multiple failures", user_id = 456, attempts = 5))
sec_logger(SEC_BREACH("Unauthorized access", user_id = 789))
```

**When to use**: Security compliance, intrusion detection, audit trails.

---

## Pattern: Performance Monitoring
**Tags**: `#performance`, `#metrics`, `#timing`, `#custom-level`

Log performance metrics with custom levels.

```{r eval=FALSE}
PERF <- log_event_level("PERF", 38)

perf_logger <- logger() %>%
  with_receivers(
    to_json() %>%
      on_s3(bucket = "metrics",
            key = "performance.jsonl")
  ) %>%
  with_tags("performance")

timed_operation <- function(op_name, expr) {
  start <- Sys.time()
  result <- expr
  duration_ms <- as.numeric(difftime(Sys.time(), start, units = "secs")) * 1000

  perf_logger(PERF("Operation complete",
                   operation = op_name,
                   duration_ms = duration_ms))

  result
}

# Usage
result <- timed_operation("database_query", {
  # ... expensive operation ...
})
```

**When to use**: Performance analysis, SLA monitoring, optimization.

---

## Pattern: Middleware for Event Transformation
**Tags**: `#middleware`, `#transformation`, `#pipeline`, `#cross-cutting`

Transform events before they reach receivers using middleware.

### What is Middleware?

Middleware functions transform log events in a pipeline:

```
Event → Middleware 1 → Middleware 2 → Logger Filter → Receivers
```

Each middleware can:
- Transform the event (add fields, modify message)
- Drop the event (return NULL to short-circuit)
- Pass through unchanged

### Basic Middleware

```{r eval=FALSE}
# Create middleware function
add_hostname <- middleware(function(event) {
  event$hostname <- Sys.info()[["nodename"]]
  event
})

# Apply to logger
log_this <- logger() %>%
  with_middleware(add_hostname) %>%
  with_receivers(to_json() %>% on_local("app.jsonl"))

log_this(NOTE("Test message"))
# → JSON includes "hostname": "server-01"
```

**When to use**: Add context automatically, reduce repetitive code, centralize transformations.

### PII Redaction

```{r eval=FALSE}
# Redact credit cards
redact_cc <- middleware(function(event) {
  event$message <- gsub(
    "(\\d{4})[-\\s]?(\\d{4})[-\\s]?(\\d{4})[-\\s]?(\\d{4})",
    "****-****-****-\\4",
    event$message
  )
  event
})

# Redact emails
redact_email <- middleware(function(event) {
  event$message <- gsub(
    "\\b[A-Za-z0-9._%+-]+@([A-Za-z0-9.-]+\\.[A-Za-z]{2,})\\b",
    "***@\\1",
    event$message
  )
  event
})

log_this <- logger() %>%
  with_middleware(redact_cc, redact_email) %>%
  with_receivers(
    to_console(),
    to_json() %>% on_local("app.jsonl")
  )

log_this(NOTE("Payment: card 4532-1234-5678-9010 for user@example.com"))
# Output: "Payment: card ****-****-****-9010 for ***@example.com"
```

**When to use**: GDPR compliance, HIPAA compliance, protect sensitive data, production logging.

### Context Enrichment

```{r eval=FALSE}
# Add application context
add_app_context <- middleware(function(event) {
  event$app_name <- "my-api"
  event$app_version <- "1.2.3"
  event$environment <- Sys.getenv("ENV", "development")
  event$hostname <- Sys.info()[["nodename"]]
  event
})

# Add request ID (distributed tracing)
add_request_id <- function(request_id) {
  middleware(function(event) {
    event$request_id <- request_id
    event
  })
}

# Apply multiple middleware
handle_request <- function(req) {
  request_id <- req$headers[["X-Request-ID"]] %||% generate_id()

  log_this <- logger() %>%
    with_middleware(
      add_app_context,
      add_request_id(request_id)
    ) %>%
    with_receivers(to_json() %>% on_local("requests.jsonl"))

  log_this(NOTE("Request received", method = req$method, path = req$path))
  # → Includes app_name, app_version, environment, hostname, request_id
}
```

**When to use**: Microservices, distributed tracing, observability, multi-tenant apps.

### Performance Timing

```{r eval=FALSE}
# Calculate duration from start_time field
add_duration <- middleware(function(event) {
  if (!is.null(event$start_time)) {
    event$duration_ms <- as.numeric(Sys.time() - event$start_time) * 1000
    event$start_time <- NULL  # Remove from output
  }
  event
})

# Classify performance
classify_performance <- middleware(function(event) {
  if (!is.null(event$duration_ms)) {
    if (event$duration_ms < 100) {
      event$performance_class <- "fast"
    } else if (event$duration_ms < 1000) {
      event$performance_class <- "acceptable"
    } else {
      event$performance_class <- "slow"
    }
  }
  event
})

log_this <- logger() %>%
  with_middleware(add_duration, classify_performance) %>%
  with_receivers(to_console())

start_time <- Sys.time()
# ... expensive operation ...
Sys.sleep(0.5)
log_this(NOTE("Query completed", start_time = start_time))
# Output: duration_ms: 500, performance_class: acceptable
```

**When to use**: API monitoring, query optimization, SLA tracking, performance analysis.

### Event Sampling (Volume Control)

```{r eval=FALSE}
# Sample DEBUG events (keep only 10%)
sample_debug <- middleware(function(event) {
  if (event$level_class == "DEBUG" && runif(1) > 0.1) {
    return(NULL)  # Drop event
  }
  event
})

# Level-based sampling
sample_by_level <- middleware(function(event) {
  # Keep all warnings and errors
  if (event$level_number >= attr(WARNING, "level_number")) {
    return(event)
  }

  # Sample DEBUG at 1%
  if (event$level_class == "DEBUG" && runif(1) > 0.01) {
    return(NULL)
  }

  # Sample NOTE at 10%
  if (event$level_class == "NOTE" && runif(1) > 0.1) {
    return(NULL)
  }

  event
})

log_this <- logger() %>%
  with_middleware(sample_by_level) %>%
  with_receivers(to_json() %>% on_local("app.jsonl"))

# High-frequency DEBUG logs are sampled aggressively
for (i in 1:1000) {
  log_this(DEBUG(paste("Event", i)))  # Only ~10 logged
}
```

**When to use**: High-throughput systems, cost reduction (cloud logging), production optimization.

### Event Routing

```{r eval=FALSE}
# Add routing flags with middleware
route_events <- middleware(function(event) {
  # Critical errors go to PagerDuty
  if (event$level_number >= attr(ERROR, "level_number")) {
    event$route_to_pagerduty <- TRUE
  }

  # Security events go to SIEM
  if (!is.null(event$tags) && "security" %in% event$tags) {
    event$route_to_siem <- TRUE
  }

  event
})

# Receivers filter on flags
pagerduty_receiver <- receiver(function(event) {
  if (isTRUE(event$route_to_pagerduty)) {
    # ... send to PagerDuty
  }
  invisible(NULL)
})

log_this <- logger() %>%
  with_middleware(route_events) %>%
  with_receivers(
    pagerduty_receiver,
    to_json() %>% on_local("app.jsonl")  # All events
  )
```

**When to use**: Multi-destination routing, conditional alerting, event classification.

### Logger Chaining (Hierarchical Logging)

```{r eval=FALSE}
# Global logger (errors to S3)
log_global <- logger() %>%
  with_middleware(add_app_context) %>%
  with_limits(lower = ERROR) %>%
  with_receivers(to_json() %>% on_s3(bucket = "global-logs", key = "errors.jsonl"))

# Application logger (all events)
log_app <- logger() %>%
  with_middleware(add_app_context, add_duration) %>%
  with_receivers(to_json() %>% on_local("app.jsonl"))

# Component logger (database-specific)
log_db <- logger() %>%
  with_middleware(add_duration, classify_performance) %>%
  with_tags("database") %>%
  with_receivers(to_text() %>% on_local("database.log"))

# Chain loggers
ERROR("Database connection failed", retry_count = 3) %>%
  log_global() %>%   # → S3 (global errors)
  log_app() %>%      # → local app.jsonl
  log_db()           # → database.log

# Event flows through all loggers in chain
```

**When to use**: Centralized error logging, multi-tier architectures, different concerns per logger.

### Middleware Execution Order

```{r eval=FALSE}
# Order matters!
log_this <- logger() %>%
  with_middleware(
    # 1. Security first (redact PII before anything else)
    redact_pii,

    # 2. Enrichment (add context)
    add_app_context,
    add_request_id,

    # 3. Performance (calculate durations)
    add_duration,
    classify_performance,

    # 4. Routing (add flags)
    route_events,

    # 5. Sampling last (after enrichment, reduce volume)
    sample_by_level
  ) %>%
  with_receivers(
    to_console(lower = WARNING),
    to_json() %>% on_local("app.jsonl")
  )
```

**When to use**: Always order middleware intentionally - security first, sampling last.

### Short-Circuiting (Dropping Events)

```{r eval=FALSE}
# Middleware can drop events by returning NULL
drop_noisy_events <- middleware(function(event) {
  # Drop frequent cache hit messages
  if (grepl("cache hit", event$message, ignore.case = TRUE)) {
    return(NULL)
  }

  event
})

log_this <- logger() %>%
  with_middleware(drop_noisy_events) %>%
  with_receivers(to_console())

log_this(DEBUG("Cache hit for key: user_123"))  # Dropped
log_this(WARNING("Cache miss, slow query"))     # Kept
```

**When to use**: Filter noise, implement business rules, conditional logging.

### Scope-Based Middleware Chaining

```{r eval=FALSE}
# Parent logger with middleware
log_this <- logger() %>%
  with_middleware(add_app_context) %>%
  with_receivers(to_console())

log_this(NOTE("Parent scope"))  # Has app context

# Child scope adds MORE middleware
my_function <- function() {
  log_this <- log_this %>%
    with_middleware(add_request_id("REQ-123"))

  log_this(NOTE("Child scope"))  # Has app context AND request ID
}
my_function()

# Back to parent scope
log_this(NOTE("Parent again"))  # Only app context
```

**When to use**: Function-specific context, request-scoped loggers, modular systems.

### Pharmaceutical/GxP Example

```{r eval=FALSE}
# GxP-compliant middleware stack
redact_patient_ids <- middleware(function(event) {
  # Redact patient identifiers
  event$message <- gsub(
    "\\b(PT|PATIENT|SUBJECT)-?\\d+\\b",
    "[PATIENT-ID-REDACTED]",
    event$message,
    ignore.case = TRUE
  )
  event
})

add_gxp_context <- function(study_id, operator_id) {
  middleware(function(event) {
    event$study_id <- study_id
    event$operator_id <- operator_id
    event$system_id <- "LIMS-PROD-001"
    event$timestamp_iso <- format(event$time, "%Y-%m-%dT%H:%M:%S%z")
    event
  })
}

# NEVER drop audit-critical events
sample_gxp_safe <- middleware(function(event) {
  critical_tags <- c("GxP", "audit_trail", "21CFR11", "regulatory")

  # Never drop audit tags
  if (!is.null(event$tags) && any(event$tags %in% critical_tags)) {
    return(event)
  }

  # Never drop warnings/errors
  if (event$level_number >= attr(WARNING, "level_number")) {
    return(event)
  }

  # Sample DEBUG only
  if (event$level_class == "DEBUG" && runif(1) > 0.05) {
    return(NULL)
  }

  event
})

log_clinical <- logger() %>%
  with_middleware(
    redact_patient_ids,
    add_gxp_context(study_id = "TRIAL-2024-001", operator_id = "OP-12345"),
    sample_gxp_safe
  ) %>%
  with_tags("GxP", "audit_trail") %>%
  with_receivers(
    to_json() %>% on_local("gxp_audit.jsonl")
  )

log_clinical(NOTE("Sample analysis completed", sample_id = "SMP-001"))
# → Includes study_id, operator_id, system_id, timestamp_iso
# → Patient IDs redacted
# → Never dropped (audit tag)
```

**When to use**: 21 CFR Part 11 compliance, clinical trials, pharmaceutical manufacturing.

### More Examples

See `examples/middleware/` for comprehensive examples:
- `redact_pii.R` - Credit card, SSN, email redaction
- `add_context.R` - System, application, user context enrichment
- `add_shiny_context.R` - Shiny session, reactive context
- `add_timing.R` - Duration calculation, performance classification
- `sample_events.R` - Percentage, level-based, adaptive sampling

---

## Pattern Index

| Pattern | Tags | Section |
|---------|------|---------|
| Basic Logging | `#basic`, `#console` | [Link](#pattern-basic-logging) |
| Multi-Destination | `#multi-destination`, `#console`, `#file`, `#s3` | [Link](#pattern-multi-destination-logging) |
| Tiered Filtering | `#filtering`, `#levels`, `#performance` | [Link](#pattern-tiered-filtering) |
| File Rotation | `#file`, `#rotation`, `#disk-management` | [Link](#pattern-file-rotation) |
| Tagged Events | `#tagging`, `#categorization` | [Link](#pattern-tagged-events) |
| Custom Fields | `#custom-fields`, `#context`, `#structured` | [Link](#pattern-custom-fields) |
| Custom Template | `#formatting`, `#template` | [Link](#pattern-custom-template) |
| Scope Enhancement | `#scope`, `#immutability` | [Link](#pattern-scope-based-enhancement) |
| Pipeline Logging | `#pipeline`, `#dplyr`, `#chaining` | [Link](#pattern-pipeline-logging) |
| Conditional Logging | `#conditional`, `#performance` | [Link](#pattern-conditional-logging) |
| Error Handling | `#errors`, `#resilience` | [Link](#pattern-error-handling) |
| Custom Level | `#custom-level`, `#domain-specific` | [Link](#pattern-custom-log-level) |
| Prod vs Dev | `#environment`, `#configuration` | [Link](#pattern-production-vs-development) |
| Disable Logging | `#performance`, `#void` | [Link](#pattern-disable-logging-performance) |
| Config-Driven | `#configuration`, `#yaml` | [Link](#pattern-config-driven-setup) |
| Batch Processing | `#batch`, `#checkpoint`, `#progress` | [Link](#pattern-batch-processing-with-checkpoints) |
| Request Tracing | `#tracing`, `#request-id`, `#distributed` | [Link](#pattern-request-tracing) |
| Security Events | `#security`, `#audit`, `#compliance` | [Link](#pattern-security-event-logging) |
| Performance Monitoring | `#performance`, `#metrics`, `#timing` | [Link](#pattern-performance-monitoring) |
| **Middleware** | `#middleware`, `#transformation`, `#pipeline` | [Link](#pattern-middleware-for-event-transformation) |

---

## See Also

- [Getting Started](getting-started.html) - Basic usage guide
- [Tagging and Provenance](tagging-and-provenance.html) - Deep dive on tagging
- **[GxP Compliance](gxp-compliance.html) - Pharmaceutical and clinical logging patterns**
- `.claude/use-cases.md` - Detailed use case mappings
- `.claude/decision-tree.md` - Decision tree for common tasks
